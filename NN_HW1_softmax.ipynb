{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def hypothesis(X, w_1,b_1): \n",
    "\n",
    "    h= softmax(np.dot(X, w_1)+b_1)\n",
    "    return h \n",
    "  \n",
    "# function to compute gradient of error function \n",
    "def gradient(X, y, w_1,b_1): \n",
    "    h = hypothesis(X, w_1,b_1)\n",
    "    grad_soft = np.zeros([X.shape[0],10])\n",
    "    for i in range(X.shape[0]):\n",
    "        label = np.argmax(y[i])\n",
    "        grad_soft[i] = -1*h[i]\n",
    "        grad_soft[i][label] = (1-h[i][label])\n",
    "    grad_w = np.dot(X.transpose(), grad_soft) \n",
    "    grad_b = np.sum(grad_soft,axis = 0)\n",
    "    return grad_w, grad_b\n",
    "\n",
    "  \n",
    "# function to create a list containing mini-batches \n",
    "def create_mini_batches(X, y, batchsize): \n",
    "    mini_batches = [] \n",
    "    n_minibatches = X.shape[0] // batchsize \n",
    "    i = 0\n",
    "  \n",
    "    for i in range(n_minibatches): \n",
    "        X_mini = X[i*batchsize:(i+1)*batchsize] \n",
    "        Y_mini = y[i*batchsize:(i+1)*batchsize] \n",
    "        mini_batches.append((X_mini, Y_mini)) \n",
    "    if X.shape[0] % batchsize != 0: \n",
    "        X_mini = X[i*batchsize: X.shape[0]]\n",
    "        Y_mini = y[i*batchsize: X.shape[0]]\n",
    "        mini_batches.append((X_mini, Y_mini)) \n",
    "    return mini_batches \n",
    "  \n",
    "def sigmoid(x):\n",
    "     return 1/(1+np.exp(-x))\n",
    "    \n",
    "def softmax(x):\n",
    "    x = x - np.max(x,axis =1).reshape(-1,1)\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x / np.sum(exp_x,axis =1).reshape(-1,1)\n",
    "    return softmax_x\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def relu_diff(x):\n",
    "    if x >0 :\n",
    "        return float(1)\n",
    "    else :\n",
    "        return float(0)\n",
    "    \n",
    "def cross_entropy(y_pred,y_label) :\n",
    "    loss = 0\n",
    "    datasize = y_pred.shape[0]\n",
    "    for q in range(10):\n",
    "        for j in range(datasize):\n",
    "            if y_label[j][q] == 1:\n",
    "                loss += -1*math.log(y_pred[j][q])\n",
    "    loss = round(loss/datasize,2)\n",
    "    return loss\n",
    "\n",
    "def accuracy(y_pred,y_label) :\n",
    "    datasize = y_pred.shape[0]\n",
    "    error = 0\n",
    "    for j in range(datasize):\n",
    "        if np.argmax(y_pred[j]) != np.argmax(y_label[j]) :\n",
    "            error += 1\n",
    "    acc = round(100*(datasize-error)/datasize ,2)\n",
    "    return acc\n",
    "\n",
    "def train(x,y_label,w_1,b_1,batch_size,valid_split,epoch,lr):\n",
    "    datasize = x.shape[0]\n",
    "    learning_curve_train =[]\n",
    "    learning_curve_valid =[]\n",
    "    loss_curve_train =[]\n",
    "    loss_curve_valid =[]\n",
    "    trainsize = int(datasize*(1-valid_split))\n",
    "    validsize = int(datasize*valid_split)\n",
    "    for i in range(epoch):\n",
    "        if i != 0:\n",
    "            per = np.random.permutation(x.shape[0])\n",
    "            x = x[per, :]\n",
    "            y_label = y_label[per,:]\n",
    "        print('epoch : ', i+1)\n",
    "        mini_batches = create_mini_batches(x, y_label, batch_size) \n",
    "        for mini_batch in mini_batches: \n",
    "            X_mini, y_mini = mini_batch \n",
    "            grad_w, grad_b = gradient(X_mini, y_mini, w_1,b_1) \n",
    "            w_1 = w_1 + lr *grad_w\n",
    "            b_1 = b_1 + lr *grad_b\n",
    "\n",
    "\n",
    "        y_predict_train = softmax(np.dot(x[:trainsize],w_1)+b_1)\n",
    "        y_predict_valid = softmax(np.dot(x[trainsize:],w_1)+b_1)\n",
    "            \n",
    "            \n",
    "        acc_train = accuracy(y_predict_train,y_label[:trainsize])\n",
    "        acc_valid = accuracy(y_predict_valid,y_label[trainsize:])\n",
    "        learning_curve_train.append(acc_train)\n",
    "        learning_curve_valid.append(acc_valid)\n",
    "        print('accuracy_train : ', acc_train,'%')\n",
    "        print('accuracy_validation : ', acc_valid,'%')\n",
    "        loss_train = cross_entropy(y_predict_train,y_label[:trainsize])\n",
    "        loss_valid = cross_entropy(y_predict_valid,y_label[trainsize:])\n",
    "        loss_curve_train.append(loss_train)\n",
    "        loss_curve_valid.append(loss_valid)\n",
    "        print(\"loss_train\",loss_train)\n",
    "        print(\"loss_validation\",loss_valid)\n",
    "        \n",
    "    e = list(range(1,epoch+1))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(e,learning_curve_train,label='train',color ='b')\n",
    "    plt.plot(e,learning_curve_valid,label ='validation',color ='r')\n",
    "    plt.xlabel('epoch', fontsize = 12)\n",
    "    plt.ylabel('accuracy', fontsize = 12)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.subplot(122)\n",
    "    plt.plot(e,loss_curve_train,label ='train',color ='b')\n",
    "    plt.plot(e,loss_curve_valid,label='validation',color = 'r')\n",
    "    plt.xlabel('epoch', fontsize = 12)\n",
    "    plt.ylabel('loss', fontsize = 12)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.subplots_adjust(wspace =1, hspace =0)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return w_1,b_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-dd3b15eaeab1>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\king\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\king\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\king\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\king\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\king\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "train_x = mnist.train.images\n",
    "train_y = mnist.train.labels\n",
    "test_x = mnist.test.images\n",
    "test_y = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  1\n",
      "accuracy_train :  85.67 %\n",
      "accuracy_validation :  87.03 %\n",
      "loss_train 0.47\n",
      "loss_validation 0.43\n",
      "epoch :  2\n",
      "accuracy_train :  88.46 %\n",
      "accuracy_validation :  88.65 %\n",
      "loss_train 0.39\n",
      "loss_validation 0.39\n",
      "epoch :  3\n",
      "accuracy_train :  89.76 %\n",
      "accuracy_validation :  89.61 %\n",
      "loss_train 0.36\n",
      "loss_validation 0.35\n",
      "epoch :  4\n",
      "accuracy_train :  90.36 %\n",
      "accuracy_validation :  90.05 %\n",
      "loss_train 0.34\n",
      "loss_validation 0.35\n",
      "epoch :  5\n",
      "accuracy_train :  90.65 %\n",
      "accuracy_validation :  90.6 %\n",
      "loss_train 0.33\n",
      "loss_validation 0.34\n",
      "epoch :  6\n",
      "accuracy_train :  90.79 %\n",
      "accuracy_validation :  90.88 %\n",
      "loss_train 0.32\n",
      "loss_validation 0.32\n",
      "epoch :  7\n",
      "accuracy_train :  91.03 %\n",
      "accuracy_validation :  91.35 %\n",
      "loss_train 0.32\n",
      "loss_validation 0.31\n",
      "epoch :  8\n",
      "accuracy_train :  91.31 %\n",
      "accuracy_validation :  91.09 %\n",
      "loss_train 0.31\n",
      "loss_validation 0.32\n",
      "epoch :  9\n",
      "accuracy_train :  91.42 %\n",
      "accuracy_validation :  91.49 %\n",
      "loss_train 0.3\n",
      "loss_validation 0.31\n",
      "epoch :  10\n",
      "accuracy_train :  91.46 %\n",
      "accuracy_validation :  91.82 %\n",
      "loss_train 0.3\n",
      "loss_validation 0.29\n",
      "epoch :  11\n",
      "accuracy_train :  91.65 %\n",
      "accuracy_validation :  91.65 %\n",
      "loss_train 0.3\n",
      "loss_validation 0.3\n",
      "epoch :  12\n",
      "accuracy_train :  91.76 %\n",
      "accuracy_validation :  91.93 %\n",
      "loss_train 0.29\n",
      "loss_validation 0.29\n",
      "epoch :  13\n",
      "accuracy_train :  91.81 %\n",
      "accuracy_validation :  91.84 %\n",
      "loss_train 0.29\n",
      "loss_validation 0.29\n",
      "epoch :  14\n",
      "accuracy_train :  91.9 %\n",
      "accuracy_validation :  92.05 %\n",
      "loss_train 0.29\n",
      "loss_validation 0.29\n",
      "epoch :  15\n",
      "accuracy_train :  91.99 %\n",
      "accuracy_validation :  91.88 %\n",
      "loss_train 0.28\n",
      "loss_validation 0.29\n",
      "epoch :  16\n",
      "accuracy_train :  92.04 %\n",
      "accuracy_validation :  92.15 %\n",
      "loss_train 0.28\n",
      "loss_validation 0.28\n",
      "epoch :  17\n",
      "accuracy_train :  92.04 %\n",
      "accuracy_validation :  92.49 %\n",
      "loss_train 0.29\n",
      "loss_validation 0.27\n",
      "epoch :  18\n",
      "accuracy_train :  92.1 %\n",
      "accuracy_validation :  92.45 %\n",
      "loss_train 0.28\n",
      "loss_validation 0.27\n",
      "epoch :  19\n",
      "accuracy_train :  92.24 %\n",
      "accuracy_validation :  92.34 %\n",
      "loss_train 0.28\n",
      "loss_validation 0.28\n",
      "epoch :  20\n",
      "accuracy_train :  92.18 %\n",
      "accuracy_validation :  92.19 %\n",
      "loss_train 0.28\n",
      "loss_validation 0.28\n",
      "epoch :  21\n",
      "accuracy_train :  92.34 %\n",
      "accuracy_validation :  92.66 %\n",
      "loss_train 0.28\n",
      "loss_validation 0.27\n",
      "epoch :  22\n",
      "accuracy_train :  92.29 %\n",
      "accuracy_validation :  92.61 %\n",
      "loss_train 0.28\n",
      "loss_validation 0.27\n",
      "epoch :  23\n",
      "accuracy_train :  92.3 %\n",
      "accuracy_validation :  92.54 %\n",
      "loss_train 0.28\n",
      "loss_validation 0.27\n",
      "epoch :  24\n",
      "accuracy_train :  92.4 %\n",
      "accuracy_validation :  92.65 %\n",
      "loss_train 0.28\n",
      "loss_validation 0.27\n",
      "epoch :  25\n",
      "accuracy_train :  92.35 %\n",
      "accuracy_validation :  92.99 %\n",
      "loss_train 0.27\n",
      "loss_validation 0.26\n",
      "epoch :  26\n",
      "accuracy_train :  92.55 %\n",
      "accuracy_validation :  92.13 %\n",
      "loss_train 0.27\n",
      "loss_validation 0.29\n",
      "epoch :  27\n",
      "accuracy_train :  92.48 %\n",
      "accuracy_validation :  92.65 %\n",
      "loss_train 0.27\n",
      "loss_validation 0.26\n",
      "epoch :  28\n",
      "accuracy_train :  92.51 %\n",
      "accuracy_validation :  92.58 %\n",
      "loss_train 0.27\n",
      "loss_validation 0.27\n",
      "epoch :  29\n",
      "accuracy_train :  92.44 %\n",
      "accuracy_validation :  92.64 %\n",
      "loss_train 0.27\n",
      "loss_validation 0.27\n",
      "epoch :  30\n",
      "accuracy_train :  92.55 %\n",
      "accuracy_validation :  92.38 %\n",
      "loss_train 0.27\n",
      "loss_validation 0.27\n",
      "epoch :  31\n",
      "accuracy_train :  92.52 %\n",
      "accuracy_validation :  92.49 %\n",
      "loss_train 0.27\n",
      "loss_validation 0.28\n",
      "epoch :  32\n",
      "accuracy_train :  92.52 %\n",
      "accuracy_validation :  93.05 %\n",
      "loss_train 0.27\n",
      "loss_validation 0.25\n",
      "epoch :  33\n",
      "accuracy_train :  92.7 %\n",
      "accuracy_validation :  92.24 %\n",
      "loss_train 0.26\n",
      "loss_validation 0.28\n",
      "epoch :  34\n",
      "accuracy_train :  92.6 %\n",
      "accuracy_validation :  92.99 %\n",
      "loss_train 0.27\n",
      "loss_validation 0.26\n",
      "epoch :  35\n",
      "accuracy_train :  92.68 %\n",
      "accuracy_validation :  93.04 %\n",
      "loss_train 0.27\n",
      "loss_validation 0.25\n",
      "epoch :  36\n",
      "accuracy_train :  92.67 %\n",
      "accuracy_validation :  92.84 %\n",
      "loss_train 0.26\n",
      "loss_validation 0.26\n",
      "epoch :  37\n",
      "accuracy_train :  92.73 %\n",
      "accuracy_validation :  92.72 %\n",
      "loss_train 0.26\n",
      "loss_validation 0.26\n",
      "epoch :  38\n",
      "accuracy_train :  92.6 %\n",
      "accuracy_validation :  92.78 %\n",
      "loss_train 0.26\n",
      "loss_validation 0.26\n",
      "epoch :  39\n",
      "accuracy_train :  92.88 %\n",
      "accuracy_validation :  92.39 %\n",
      "loss_train 0.26\n",
      "loss_validation 0.27\n",
      "epoch :  40\n",
      "accuracy_train :  92.73 %\n",
      "accuracy_validation :  93.15 %\n",
      "loss_train 0.26\n",
      "loss_validation 0.25\n",
      "epoch :  41\n",
      "accuracy_train :  92.87 %\n",
      "accuracy_validation :  92.65 %\n",
      "loss_train 0.26\n",
      "loss_validation 0.26\n",
      "epoch :  42\n",
      "accuracy_train :  92.83 %\n",
      "accuracy_validation :  92.81 %\n",
      "loss_train 0.26\n",
      "loss_validation 0.26\n",
      "epoch :  43\n",
      "accuracy_train :  92.78 %\n",
      "accuracy_validation :  92.99 %\n",
      "loss_train 0.26\n",
      "loss_validation 0.25\n",
      "epoch :  44\n",
      "accuracy_train :  92.79 %\n",
      "accuracy_validation :  93.22 %\n",
      "loss_train 0.26\n",
      "loss_validation 0.25\n",
      "epoch :  45\n",
      "accuracy_train :  92.84 %\n",
      "accuracy_validation :  92.96 %\n",
      "loss_train 0.26\n",
      "loss_validation 0.26\n",
      "epoch :  46\n",
      "accuracy_train :  92.83 %\n",
      "accuracy_validation :  93.18 %\n",
      "loss_train 0.26\n",
      "loss_validation 0.26\n",
      "epoch :  47\n",
      "accuracy_train :  92.82 %\n",
      "accuracy_validation :  93.03 %\n",
      "loss_train 0.26\n",
      "loss_validation 0.25\n",
      "epoch :  48\n",
      "accuracy_train :  92.8 %\n",
      "accuracy_validation :  93.02 %\n",
      "loss_train 0.26\n",
      "loss_validation 0.26\n",
      "epoch :  49\n",
      "accuracy_train :  93.01 %\n",
      "accuracy_validation :  92.77 %\n",
      "loss_train 0.26\n",
      "loss_validation 0.26\n",
      "epoch :  50\n",
      "accuracy_train :  92.84 %\n",
      "accuracy_validation :  93.25 %\n",
      "loss_train 0.26\n",
      "loss_validation 0.24\n",
      "epoch :  51\n",
      "accuracy_train :  92.87 %\n",
      "accuracy_validation :  92.94 %\n",
      "loss_train 0.26\n",
      "loss_validation 0.25\n",
      "epoch :  52\n",
      "accuracy_train :  92.97 %\n",
      "accuracy_validation :  92.72 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.26\n",
      "epoch :  53\n",
      "accuracy_train :  92.9 %\n",
      "accuracy_validation :  93.19 %\n",
      "loss_train 0.26\n",
      "loss_validation 0.24\n",
      "epoch :  54\n",
      "accuracy_train :  92.95 %\n",
      "accuracy_validation :  92.96 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.26\n",
      "epoch :  55\n",
      "accuracy_train :  92.99 %\n",
      "accuracy_validation :  93.16 %\n",
      "loss_train 0.26\n",
      "loss_validation 0.24\n",
      "epoch :  56\n",
      "accuracy_train :  92.97 %\n",
      "accuracy_validation :  93.08 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.25\n",
      "epoch :  57\n",
      "accuracy_train :  92.88 %\n",
      "accuracy_validation :  93.22 %\n",
      "loss_train 0.26\n",
      "loss_validation 0.25\n",
      "epoch :  58\n",
      "accuracy_train :  92.94 %\n",
      "accuracy_validation :  93.06 %\n",
      "loss_train 0.26\n",
      "loss_validation 0.24\n",
      "epoch :  59\n",
      "accuracy_train :  93.1 %\n",
      "accuracy_validation :  92.94 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.26\n",
      "epoch :  60\n",
      "accuracy_train :  92.95 %\n",
      "accuracy_validation :  93.34 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.25\n",
      "epoch :  61\n",
      "accuracy_train :  93.03 %\n",
      "accuracy_validation :  92.95 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.25\n",
      "epoch :  62\n",
      "accuracy_train :  92.95 %\n",
      "accuracy_validation :  93.26 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.24\n",
      "epoch :  63\n",
      "accuracy_train :  93.06 %\n",
      "accuracy_validation :  92.97 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.26\n",
      "epoch :  64\n",
      "accuracy_train :  93.05 %\n",
      "accuracy_validation :  93.18 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.25\n",
      "epoch :  65\n",
      "accuracy_train :  93.03 %\n",
      "accuracy_validation :  93.07 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.24\n",
      "epoch :  66\n",
      "accuracy_train :  93.01 %\n",
      "accuracy_validation :  93.52 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.24\n",
      "epoch :  67\n",
      "accuracy_train :  93.09 %\n",
      "accuracy_validation :  93.17 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.25\n",
      "epoch :  68\n",
      "accuracy_train :  93.13 %\n",
      "accuracy_validation :  93.1 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.24\n",
      "epoch :  69\n",
      "accuracy_train :  93.06 %\n",
      "accuracy_validation :  93.49 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.24\n",
      "epoch :  70\n",
      "accuracy_train :  93.05 %\n",
      "accuracy_validation :  93.1 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.26\n",
      "epoch :  71\n",
      "accuracy_train :  93.09 %\n",
      "accuracy_validation :  93.33 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.25\n",
      "epoch :  72\n",
      "accuracy_train :  93.24 %\n",
      "accuracy_validation :  92.96 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.25\n",
      "epoch :  73\n",
      "accuracy_train :  93.16 %\n",
      "accuracy_validation :  93.2 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.25\n",
      "epoch :  74\n",
      "accuracy_train :  93.17 %\n",
      "accuracy_validation :  93.18 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.24\n",
      "epoch :  75\n",
      "accuracy_train :  93.1 %\n",
      "accuracy_validation :  93.29 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.24\n",
      "epoch :  76\n",
      "accuracy_train :  93.17 %\n",
      "accuracy_validation :  93.31 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.25\n",
      "epoch :  77\n",
      "accuracy_train :  93.2 %\n",
      "accuracy_validation :  93.03 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.25\n",
      "epoch :  78\n",
      "accuracy_train :  93.24 %\n",
      "accuracy_validation :  93.08 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train 0.25\n",
      "loss_validation 0.25\n",
      "epoch :  79\n",
      "accuracy_train :  93.23 %\n",
      "accuracy_validation :  93.15 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.26\n",
      "epoch :  80\n",
      "accuracy_train :  93.15 %\n",
      "accuracy_validation :  93.24 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.25\n",
      "epoch :  81\n",
      "accuracy_train :  93.1 %\n",
      "accuracy_validation :  93.41 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.24\n",
      "epoch :  82\n",
      "accuracy_train :  93.2 %\n",
      "accuracy_validation :  93.45 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.24\n",
      "epoch :  83\n",
      "accuracy_train :  93.21 %\n",
      "accuracy_validation :  92.95 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.25\n",
      "epoch :  84\n",
      "accuracy_train :  93.1 %\n",
      "accuracy_validation :  93.57 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.24\n",
      "epoch :  85\n",
      "accuracy_train :  93.1 %\n",
      "accuracy_validation :  93.37 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.25\n",
      "epoch :  86\n",
      "accuracy_train :  93.23 %\n",
      "accuracy_validation :  93.35 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.25\n",
      "epoch :  87\n",
      "accuracy_train :  93.22 %\n",
      "accuracy_validation :  93.12 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.24\n",
      "epoch :  88\n",
      "accuracy_train :  93.33 %\n",
      "accuracy_validation :  92.98 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.26\n",
      "epoch :  89\n",
      "accuracy_train :  93.31 %\n",
      "accuracy_validation :  93.06 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.25\n",
      "epoch :  90\n",
      "accuracy_train :  93.16 %\n",
      "accuracy_validation :  92.99 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.26\n",
      "epoch :  91\n",
      "accuracy_train :  93.22 %\n",
      "accuracy_validation :  93.39 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.23\n",
      "epoch :  92\n",
      "accuracy_train :  93.35 %\n",
      "accuracy_validation :  92.91 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.26\n",
      "epoch :  93\n",
      "accuracy_train :  93.29 %\n",
      "accuracy_validation :  93.22 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.24\n",
      "epoch :  94\n",
      "accuracy_train :  93.1 %\n",
      "accuracy_validation :  93.82 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.22\n",
      "epoch :  95\n",
      "accuracy_train :  93.26 %\n",
      "accuracy_validation :  93.28 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.25\n",
      "epoch :  96\n",
      "accuracy_train :  93.27 %\n",
      "accuracy_validation :  93.39 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.23\n",
      "epoch :  97\n",
      "accuracy_train :  93.34 %\n",
      "accuracy_validation :  92.81 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.25\n",
      "epoch :  98\n",
      "accuracy_train :  93.23 %\n",
      "accuracy_validation :  93.69 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.24\n",
      "epoch :  99\n",
      "accuracy_train :  93.34 %\n",
      "accuracy_validation :  93.42 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  100\n",
      "accuracy_train :  93.3 %\n",
      "accuracy_validation :  93.39 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  101\n",
      "accuracy_train :  93.3 %\n",
      "accuracy_validation :  93.51 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.25\n",
      "epoch :  102\n",
      "accuracy_train :  93.29 %\n",
      "accuracy_validation :  93.05 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.25\n",
      "epoch :  103\n",
      "accuracy_train :  93.31 %\n",
      "accuracy_validation :  93.42 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  104\n",
      "accuracy_train :  93.35 %\n",
      "accuracy_validation :  93.26 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  105\n",
      "accuracy_train :  93.41 %\n",
      "accuracy_validation :  93.15 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.25\n",
      "epoch :  106\n",
      "accuracy_train :  93.32 %\n",
      "accuracy_validation :  93.34 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  107\n",
      "accuracy_train :  93.21 %\n",
      "accuracy_validation :  93.88 %\n",
      "loss_train 0.25\n",
      "loss_validation 0.23\n",
      "epoch :  108\n",
      "accuracy_train :  93.3 %\n",
      "accuracy_validation :  93.41 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  109\n",
      "accuracy_train :  93.28 %\n",
      "accuracy_validation :  93.37 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  110\n",
      "accuracy_train :  93.33 %\n",
      "accuracy_validation :  93.24 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  111\n",
      "accuracy_train :  93.33 %\n",
      "accuracy_validation :  93.15 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  112\n",
      "accuracy_train :  93.22 %\n",
      "accuracy_validation :  93.59 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  113\n",
      "accuracy_train :  93.28 %\n",
      "accuracy_validation :  93.47 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  114\n",
      "accuracy_train :  93.28 %\n",
      "accuracy_validation :  93.42 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  115\n",
      "accuracy_train :  93.29 %\n",
      "accuracy_validation :  93.19 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  116\n",
      "accuracy_train :  93.38 %\n",
      "accuracy_validation :  93.36 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  117\n",
      "accuracy_train :  93.38 %\n",
      "accuracy_validation :  93.45 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  118\n",
      "accuracy_train :  93.28 %\n",
      "accuracy_validation :  93.33 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.25\n",
      "epoch :  119\n",
      "accuracy_train :  93.39 %\n",
      "accuracy_validation :  93.28 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  120\n",
      "accuracy_train :  93.38 %\n",
      "accuracy_validation :  93.29 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  121\n",
      "accuracy_train :  93.39 %\n",
      "accuracy_validation :  93.25 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  122\n",
      "accuracy_train :  93.35 %\n",
      "accuracy_validation :  93.72 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  123\n",
      "accuracy_train :  93.39 %\n",
      "accuracy_validation :  93.24 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.25\n",
      "epoch :  124\n",
      "accuracy_train :  93.45 %\n",
      "accuracy_validation :  93.2 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  125\n",
      "accuracy_train :  93.3 %\n",
      "accuracy_validation :  93.53 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  126\n",
      "accuracy_train :  93.37 %\n",
      "accuracy_validation :  93.69 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  127\n",
      "accuracy_train :  93.37 %\n",
      "accuracy_validation :  93.44 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  128\n",
      "accuracy_train :  93.3 %\n",
      "accuracy_validation :  93.8 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  129\n",
      "accuracy_train :  93.42 %\n",
      "accuracy_validation :  93.55 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  130\n",
      "accuracy_train :  93.33 %\n",
      "accuracy_validation :  93.64 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  131\n",
      "accuracy_train :  93.3 %\n",
      "accuracy_validation :  93.79 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  132\n",
      "accuracy_train :  93.36 %\n",
      "accuracy_validation :  93.41 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  133\n",
      "accuracy_train :  93.4 %\n",
      "accuracy_validation :  93.35 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  134\n",
      "accuracy_train :  93.33 %\n",
      "accuracy_validation :  93.61 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  135\n",
      "accuracy_train :  93.36 %\n",
      "accuracy_validation :  93.65 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  136\n",
      "accuracy_train :  93.46 %\n",
      "accuracy_validation :  93.35 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.25\n",
      "epoch :  137\n",
      "accuracy_train :  93.47 %\n",
      "accuracy_validation :  93.2 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  138\n",
      "accuracy_train :  93.34 %\n",
      "accuracy_validation :  93.72 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  139\n",
      "accuracy_train :  93.47 %\n",
      "accuracy_validation :  93.42 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  140\n",
      "accuracy_train :  93.44 %\n",
      "accuracy_validation :  93.43 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  141\n",
      "accuracy_train :  93.28 %\n",
      "accuracy_validation :  93.53 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  142\n",
      "accuracy_train :  93.39 %\n",
      "accuracy_validation :  93.75 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  143\n",
      "accuracy_train :  93.34 %\n",
      "accuracy_validation :  93.65 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  144\n",
      "accuracy_train :  93.54 %\n",
      "accuracy_validation :  93.05 %\n",
      "loss_train 0.23\n",
      "loss_validation 0.25\n",
      "epoch :  145\n",
      "accuracy_train :  93.51 %\n",
      "accuracy_validation :  93.24 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  146\n",
      "accuracy_train :  93.39 %\n",
      "accuracy_validation :  93.49 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  147\n",
      "accuracy_train :  93.36 %\n",
      "accuracy_validation :  93.65 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.22\n",
      "epoch :  148\n",
      "accuracy_train :  93.61 %\n",
      "accuracy_validation :  92.95 %\n",
      "loss_train 0.23\n",
      "loss_validation 0.26\n",
      "epoch :  149\n",
      "accuracy_train :  93.36 %\n",
      "accuracy_validation :  93.64 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  150\n",
      "accuracy_train :  93.4 %\n",
      "accuracy_validation :  93.76 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  151\n",
      "accuracy_train :  93.4 %\n",
      "accuracy_validation :  93.83 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.22\n",
      "epoch :  152\n",
      "accuracy_train :  93.42 %\n",
      "accuracy_validation :  93.31 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  153\n",
      "accuracy_train :  93.52 %\n",
      "accuracy_validation :  93.27 %\n",
      "loss_train 0.23\n",
      "loss_validation 0.24\n",
      "epoch :  154\n",
      "accuracy_train :  93.32 %\n",
      "accuracy_validation :  93.91 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  155\n",
      "accuracy_train :  93.42 %\n",
      "accuracy_validation :  93.61 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  156\n",
      "accuracy_train :  93.5 %\n",
      "accuracy_validation :  93.36 %\n",
      "loss_train 0.23\n",
      "loss_validation 0.25\n",
      "epoch :  157\n",
      "accuracy_train :  93.34 %\n",
      "accuracy_validation :  93.68 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  158\n",
      "accuracy_train :  93.43 %\n",
      "accuracy_validation :  93.75 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  159\n",
      "accuracy_train :  93.36 %\n",
      "accuracy_validation :  93.81 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  160\n",
      "accuracy_train :  93.53 %\n",
      "accuracy_validation :  93.46 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  161\n",
      "accuracy_train :  93.44 %\n",
      "accuracy_validation :  93.36 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  162\n",
      "accuracy_train :  93.47 %\n",
      "accuracy_validation :  93.79 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  163\n",
      "accuracy_train :  93.5 %\n",
      "accuracy_validation :  93.53 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.24\n",
      "epoch :  164\n",
      "accuracy_train :  93.41 %\n",
      "accuracy_validation :  93.59 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  165\n",
      "accuracy_train :  93.43 %\n",
      "accuracy_validation :  93.64 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.22\n",
      "epoch :  166\n",
      "accuracy_train :  93.33 %\n",
      "accuracy_validation :  93.96 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.22\n",
      "epoch :  167\n",
      "accuracy_train :  93.35 %\n",
      "accuracy_validation :  93.85 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  168\n",
      "accuracy_train :  93.48 %\n",
      "accuracy_validation :  93.34 %\n",
      "loss_train 0.23\n",
      "loss_validation 0.24\n",
      "epoch :  169\n",
      "accuracy_train :  93.4 %\n",
      "accuracy_validation :  93.75 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  170\n",
      "accuracy_train :  93.53 %\n",
      "accuracy_validation :  93.45 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  171\n",
      "accuracy_train :  93.55 %\n",
      "accuracy_validation :  93.44 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  172\n",
      "accuracy_train :  93.5 %\n",
      "accuracy_validation :  93.78 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  173\n",
      "accuracy_train :  93.53 %\n",
      "accuracy_validation :  93.65 %\n",
      "loss_train 0.24\n",
      "loss_validation 0.23\n",
      "epoch :  174\n",
      "accuracy_train :  93.57 %\n",
      "accuracy_validation :  93.43 %\n"
     ]
    }
   ],
   "source": [
    "#np.seterr(divide='ignore', invalid='ignore')\n",
    "#W_1 = np.ones([784,10])\n",
    "W_1 = np.random.rand(784,10)\n",
    "b_1 = np.random.rand(1,10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "w1_train,b1_train= train(train_x,train_y,W_1,b_1,100,0.2,200,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = softmax(np.dot(test_x[z],w1_train)+b1_train)\n",
    "acc = accuracy(y_predict,test_y)\n",
    "\n",
    "print('accuracy : ', acc,'%')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
